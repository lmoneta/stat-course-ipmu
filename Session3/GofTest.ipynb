{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Goodness of Fit Test in Histogram Fitting\n",
    "\n",
    "In this example we perform several GoF tests of an histogram generated with a given distribution. \n",
    "We do the following GoF tests:  \n",
    "* Chi-square test using the Neyman Chi-square (based on the observed bin error)\n",
    "* Chi-square test using the Pearson chisquare (based on the expected bin error) \n",
    "* Chi-square test using the Baker-Cousins  likelihood ratio value. \n",
    "\n",
    "We study the obtained test statistic distribution using pseudo-experiments and we study if it is following a Chi-square distribution and for how many degree of freedom. \n",
    "\n",
    "At the end we study also the bias in the fitted function parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start creating the histogram for the data sample we are going to fit and thre different histogram for studying the 3 different test statistics used for the GoF tests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%jsroot on  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// some configuration parameters\n",
    "// number of bins used for the data histogram and data range\n",
    "int nbin = 100;         \n",
    "double xmin = 0;         \n",
    "double xmax = 20; \n",
    " \n",
    "int nexp = 1000; // number of experiments\n",
    "int n = 200;   // size of data sample for each experiment\n",
    "\n",
    "auto hist = new TH1D(\"hist\",\"Data Sample distribution\",nbin,xmin,xmax);\n",
    "auto hchi2N = new TH1D(\"hchi2N\",\"Neyman chi-square distribution\",50,0,2*nbin);\n",
    "auto hchi2P = new TH1D(\"hchi2P\",\"Pearson chi-square distribution\",50,0,2*nbin);\n",
    "auto hchi2L = new TH1D(\"hchi2L\",\"Baker-Cousins LR distribution\",50,0,2*nbin);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data distribution\n",
    "\n",
    "Here we define the function used to generate and then later fit the generated histograms. \n",
    "We use an Exponential function, but we could also use a Gaussian or even a Constant function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TF1 f1(\"f1\",\"[A]*exp(-x/[tau])\",xmin,xmax);\n",
    "double trueParams[] = {1,5};   // true parameter values used for generating the events\n",
    "double params0[] = { 10, 4};  //  initial parameter values used for fitting\n",
    "//TRandom3 rndm(0);\n",
    "f1.SetRange(0,100);\n",
    "f1.SetNpx(1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Monte Carlo Study\n",
    "\n",
    "We perform all the work in the code below. We generate a set of pseudo-exeriments (e.g. 1000) where  each one of them conists of an histogram filled with 200 events generated according to the given distribution (e.g. exponential). \n",
    "\n",
    "We perform the 3 different possible fits to the histogram and we study the resulting Chi-square distribution.\n",
    "* **Chi-square fit using the Neyman Chi-square** (based on the observed bin error). **Default** Method in ROOT\n",
    "* **Chi-square fit using the Pearson chisquare** (based on the expected bin error). **Option *P* ** in ROOT\n",
    "* **Binned likelihood fit** assuming a Poisson p.d.f for each bin. **Option *L* ** in ROOT. \n",
    "\n",
    "We study then the resulting Chi-square (test statistic) values obtained by the three fits. \n",
    "\n",
    "In case of the binned likelihood fit, the test statistics we use is the log-likelihood ratio obtained using a saturated model ( Baker-Cousins procedure, see *S. Baker and R. D. Cousins, Nucl. Instrum. Meth. 221 (1984) 437*).\n",
    "This log-likelihood ratio can be computed directly in ROOT by multiplying by 2 the minimum value of negative log-likelihood function at the minimum retrieved from the `TFitResult` class. \n",
    "\n",
    "We compare then the different chi-square obtained in the 2 different methods by collecting their values in 3 separate histograms. \n",
    "\n",
    "Note that we use `TF1::GetRandom` to generating events according to a generic distribution (e.g in this case defined by the ROOT `TF1` class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hchi2N->Reset(); // reset in case we run a second time\n",
    "hchi2P->Reset(); \n",
    "hchi2L->Reset(); \n",
    "for (int iexp = 0; iexp < nexp; ++iexp) {\n",
    "    hist->Reset();\n",
    "    f1.SetParameters(trueParams);\n",
    "    for (int i = 0; i < n; ++i){\n",
    "        hist->Fill( f1.GetRandom() );\n",
    "    }\n",
    "    // set the initial function parameters \n",
    "    f1.SetParameters(params0);\n",
    "    f1.SetLineColor(kRed);\n",
    "    f1.SetTitle(\"Neyman Fit\");\n",
    "    // Neyman chisquare fit \n",
    "    // use option Q to avoid too much printing and option 0 to avoid saving the fit function\n",
    "    auto rN = hist->Fit(&f1,\"S Q \");  \n",
    "    f1.SetParameters(params0);   // reset parameters \n",
    "    f1.SetLineColor(kBlack);\n",
    "    f1.SetTitle(\"Pearson Fit\");\n",
    "    // Pearson chisquare fit\n",
    "    auto rP = hist->Fit(&f1,\"S P Q +\");  // use option P \n",
    "    f1.SetParameters(params0);   // reset parameters \n",
    "    f1.SetLineColor(kBlue);\n",
    "    f1.SetTitle(\"Likelihood Fit\");\n",
    "    // Baker-Cousins log-likelihood fit\n",
    "    auto rL = hist->Fit(&f1,\"S Q L +\");  // use option L\n",
    "    \n",
    "    // get results from fit results and save them  in histograms \n",
    "    if (rN == 0) hchi2N->Fill( rN->Chi2 () );  \n",
    "    if (rP == 0) hchi2P->Fill( rP->Chi2 () ); \n",
    "    // to get LL value from fit result\n",
    "    if (rL == 0) hchi2L->Fill( 2.* rL->MinFcnValue() ); \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot as example one of the data set we have generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// just one example of the data \n",
    "hist->Draw();\n",
    "legend = new TLegend(0.6,0.6,0.88,0.88);\n",
    "functions = hist->GetListOfFunctions();\n",
    "// loop on the list of histogram functions and add them in the legend\n",
    "for ( auto * f : *functions) {\n",
    "    if (f->IsA()==TF1::Class())\n",
    "       legend->AddEntry(f,f->GetTitle(),\"L\");\n",
    "}\n",
    "legend->Draw();\n",
    "gPad->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot here the 3 different test statistics distribution we have obtained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "canvas = new TCanvas(\"c\",\"c\",1000,1000);\n",
    "canvas->Divide(2,2);\n",
    "canvas->cd(1); hchi2N->Draw();\n",
    "canvas->cd(2); hchi2P->Draw();\n",
    "canvas->cd(3); hchi2L->Draw();\n",
    "canvas->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit of Obtained Test Statistic distribution\n",
    "\n",
    "We study the obtained test statistics by fitting them with a Chi-Square distribution function with the number of degree of freedom as a free parameter. We fit also an irrelevant normalization constant. \n",
    "\n",
    "We start defining the chi2-distribution function we use for fitting the test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fchi2 = new TF1(\"fchi2\",\"[Constant]*ROOT::Math::chisquared_pdf(x,[ndf])\",0,100);\n",
    "// create also a new Canvas for plotting\n",
    "c2 = new TCanvas(\"c2\",\"c2\",1000,600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Neyman Chi-Square fit** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fchi2->SetParameters(hchi2N->GetEntries()*hchi2N->GetBinWidth(1), hchi2N->GetMean());\n",
    "auto rchi2N = hchi2N->Fit(fchi2,\"LS\");\n",
    "gStyle->SetOptFit(1111); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gPad->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Pearson Chi-Square fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fchi2->SetParameters(hchi2P->GetEntries()*hchi2P->GetBinWidth(1), hchi2P->GetMean());\n",
    "auto rchi2P = hchi2P->Fit(fchi2,\"LS\");\n",
    "gPad->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **Baker-Cousins Likelihood Ratio Chi-Square Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fchi2->SetParameters(hchi2L->GetEntries()*hchi2L->GetBinWidth(1), hchi2L->GetMean());\n",
    "auto rchi2L = hchi2L->Fit(fchi2,\"LS\");\n",
    "gPad->Draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::cout << \"Number of degree of freedom for Neyman chi2 distribution is \" \n",
    "    << rchi2N->Parameter(1) << \" +/- \" << rchi2N->Error(1) << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::cout << \"Number of degree of freedom for Pearson chi2 distribution is \" \n",
    "    << rchi2P->Parameter(1) << \" +/- \" << rchi2P->Error(1) << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::cout << \"Number of degree of freedom for Baker-Cousins chi2 distribution is \" \n",
    "    << rchi2L->Parameter(1) << \" +/- \" << rchi2L->Error(1) << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that the fitted number of degree of freedom is larger than the number of bins in the Baker-Cousins case. This is consistent with the study performed on the Poisson Log Likelihood ratio in a CDF note by \n",
    "*Joel G. Heinrich, “The Log Likelihood Ratio of the Poisson Distribution for Small μ,” CDF/MEMO/CDF/CDFR/5718,  http://www-cdf. fnal.gov/physics/statistics/notes/cdf5718_loglikeratv2.ps.gz\n",
    "\n",
    "One can study how the fitted number of degree of freedom changes by increasing or decreasing the true expected contents for data sample histogram.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Parameter Bias\n",
    "\n",
    "We extend the exercise by studying also the distribution of the fit parameters, $\\tau$ in the 3 different cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htauN = new TH1D(\"htauN\",\"Distribution of fitted parameter tau for Neyman Chi-squared fits\",50,0,10);\n",
    "htauP = new TH1D(\"htauP\",\"Distribution of fitted parameter tau for Pearson Chi-squared fits\",50,0,10);\n",
    "htauL = new TH1D(\"htauL\",\"Distribution of fitted parameter tau for Log-Likelihood fits\",50,0,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htauN->Reset(); // reset in case we run a second time\n",
    "htauP->Reset(); \n",
    "htauL->Reset(); \n",
    "for (int iexp = 0; iexp < nexp; ++iexp) {\n",
    "    f1.SetParameters(trueParams);  // set initial param values before generating\n",
    "    hist->Reset();\n",
    "    for (int i = 0; i < n; ++i){\n",
    "        hist->Fill( f1.GetRandom() );\n",
    "    }\n",
    "    // set the initial function parameters \n",
    "    f1.SetParameters(params0);\n",
    "    f1.SetLineColor(kRed);\n",
    "    f1.SetTitle(\"Neyman Fit\");\n",
    "    // Neyman chisquare fit \n",
    "    // use option Q to avoid too much printing and option 0 to avoid saving the fit function\n",
    "    auto rN = hist->Fit(&f1,\"S  Q\");  \n",
    "    f1.SetParameters(params0);   // reset parameters \n",
    "    f1.SetLineColor(kBlack);\n",
    "    f1.SetTitle(\"Pearson Fit\");\n",
    "    // Pearson chisquare fit\n",
    "    auto rP = hist->Fit(&f1,\"S P Q +\");  // use option P \n",
    "    f1.SetParameters(params0);   // reset parameters \n",
    "    f1.SetLineColor(kBlue);\n",
    "    f1.SetTitle(\"Likelihood Fit\");\n",
    "    // Baker-Cousins log-likelihood fit\n",
    "    \n",
    "    auto rL = hist->Fit(&f1,\"S Q L +\");  // use option L\n",
    "    \n",
    "    // get results from fit results and save them  in histograms \n",
    "    if (rN == 0) htauN->Fill( rN->Parameter(1) );  \n",
    "    if (rP == 0) htauP->Fill( rP->Parameter(1) ); \n",
    "    if (rL == 0) htauL->Fill( rL->Parameter(1) ); \n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "canvas = new TCanvas(\"c\",\"c\",1000,600);\n",
    "canvas->Divide(2,2);\n",
    "canvas->cd(1); htauN->Fit(\"gaus\",\"L\");\n",
    "canvas->cd(2); htauP->Fit(\"gaus\",\"L\");\n",
    "canvas->cd(3); htauL->Fit(\"gaus\",\"L\");\n",
    "canvas->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Parameter Bias Study for the Un-binned likelihood fit \n",
    "\n",
    "We can study also the bias in case of the unbinned likelihood fit, the same fit we perfomed in Session 2 notebook.\n",
    "\n",
    "We start by defining the C++ lambda function which computes the negative log-likelihood function (*NLL*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::vector<double> data(n); \n",
    "auto nll = [&](double * p, double *){ double sum = 0; double tau = p[0]; \n",
    "                           for (auto x_i : data) {\n",
    "  //                        sum += std::log(1./tau * std::exp(-x_i/tau));\n",
    "                            sum += - (std::log(tau) + x_i/tau );\n",
    "                           }         \n",
    "                           return -sum; \n",
    "                          };"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute now the bias by generating *nexp* experiments and perfom the unbinned maximum likelihood fit for each of them. \n",
    "\n",
    "We find the best fit parameter *tau* by finding the minimum of the *NLL* function defined above which evaluates on the data, which sre generated for each single pseudo-experiment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "htauUL = new TH1D(\"htauUL\",\"Distribution of fitted parameter tau for Unbinned Log-Likelihood fits\",50,0,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::cout << \"Generate \" << n << \" events for \" << nexp << \" experiments\" << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htauUL->Reset(); \n",
    "f1.SetParameters(trueParams);  // set initial param values \n",
    "// need to define a large range because we defined a nll normalized in the [0,inf] range\n",
    "//f1.SetRange(0,100);\n",
    "//f1.SetNpx(1000);  \n",
    "for (int iexp = 0; iexp < nexp; ++iexp) {\n",
    " \n",
    "    // generate the data vector\n",
    "    for (int i = 0; i < n; ++i){\n",
    "      data[i] = f1.GetRandom();\n",
    "    }\n",
    "    \n",
    "    // create nll function on the generated data \n",
    "    \n",
    "    TF1 fnll(\"fnll\",nll,0,50,0);\n",
    "    \n",
    "    // find the nll minimum\n",
    "    \n",
    "    double tau_best = fnll.GetMinimumX(1,20);\n",
    "    \n",
    "    // fill histogram with best parameter value\n",
    "    \n",
    "    htauUL->Fill(tau_best);\n",
    "    double h = fnll.Derivative2(tau_best);\n",
    "    //double error = sqrt(1./h);\n",
    "    //std::cout << tau_best << \"  \" << error << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gPad = canvas->cd(4);\n",
    "htauUL->Draw();\n",
    "htauUL->Fit(\"gaus\",\"L\");\n",
    "canvas->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can modify this exercise and use instead of an exponential distribution, a normal distribution. In this case one can study the bias for the sigma of the gaussian using the three different methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
